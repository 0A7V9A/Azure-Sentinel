{
  "cells": [
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Title: Alert Investigation (Process Alerts)\nLogAnalytics\nVersion 0.3\n## Description:\nSeries of modules designed to help get a better understanding of the contents of a process-based alert.\n"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "<a id='toc'></a>\n## Table of Contents\n- [Setup and Authenticate](#setup)\n\n- [Get Alerts List](#getalertslist)\n- [Choose an Alert to investigate](#enteralertid)\n  - [Extract Properties and entities from alert](#extractalertproperties)\n  - [Entity Graph](#entitygraph)\n- [Related Alerts](#related_alerts)\n- [Session Process Tree](#processtree)\n  - [Process Timeline](#processtimeline)\n- [Other Process on Host](#process_clustering)\n- [Check for IOCs in Commandline](#cmdlineiocs)\n  - [VirusTotal lookup](#virustotallookup)\n- [Alert command line - Occurrence on other hosts in subscription](#cmdlineonotherhosts)\n- [Host Logons](#host_logons)\n  - [Alert Account](#logonaccount)\n  - [Failed Logons](#failed_logons)\n- [Appendices](#appendices)\n  - [Saving data to Excel](#appendices)\n"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "<a id='setup'></a>[Contents](#toc)\n# Setup\n\n1. Make sure that you have installed packages specified in the setup (uncomment the lines to execute)\n2. There are some manual steps up to selecting the alert ID. After this most of the notebook can be executed sequentially\n3. Major sections should be executable independently (e.g. Alert Command line and Host Logons can be run skipping Session Process Tree)\n\n## Install Packages"
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": false
      },
      "cell_type": "code",
      "source": "# You may needs these - should only need to uncomment and run once\n!pip install git+https://github.com/ianhelle/msticpy --upgrade  --user\n!pip install Kqlmagic --no-cache-dir --upgrade --user\n\n# Provisional location\n\n# !pip install msgpack\n# !pip install Kqlmagic --no-cache-dir  --upgrade\n\n# !pip install PyHamcrest\n# !conda install -c conda-forge python-levenshtein -y\n# !conda install requests\n# !conda install attrs\n# !conda install seaborn\n# !conda install bokeh\n# !conda install holoviews\n\n!pip uninstall attr --yes",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Bugs:\n    \n!pip uninstall attr --yes\nnetworkx may be installed\n\n"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Import Python Packages"
    },
    {
      "metadata": {
        "scrolled": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Imports\nimport sys\nMIN_REQ_PYTHON = (3,6)\nif sys.version_info < MIN_REQ_PYTHON:\n    print('Check the Kernel->Change Kernel menu and ensure that Python 3.6')\n    print('or later is selected as the active kernel.')\n    sys.exit(\"Python %s.%s or later is required.\\n\" % MIN_REQ_PYTHON)\n\n\nimport numpy as np\nfrom IPython import get_ipython\nfrom IPython.display import display, HTML\nimport ipywidgets as widgets\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport networkx as nx\nsns.set()\nimport pandas as pd\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 50)\npd.set_option('display.max_colwidth', 100)\n\n \nimport msticpy.sectools as sectools\nimport msticpy.nbtools as mas\nimport msticpy.nbtools.kql as qry\nimport msticpy.nbtools.nbdisplay as nbdisp\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "tags": [
          "remove"
        ]
      },
      "cell_type": "markdown",
      "source": "### Enter or confirm WorkspaceId\nTo find your Workspace Id go to [Log Analytics](#https://ms.portal.azure.com/#blade/HubsExtension/Resources/resourceType/Microsoft.OperationalInsights%2Fworkspaces). Look at the workspace properties to find the ID."
    },
    {
      "metadata": {
        "tags": [
          "todo"
        ],
        "trusted": true
      },
      "cell_type": "code",
      "source": "path = %env PATH\ndsvm = False\nif '/dsvm/' in path:\n    dsvm = True\n    \nif dsvm == False:\n    # Run this if you are using Free Compute\n    from utils import config_reader as mod\n    workspace_id = mod.config_reader.read_config_values(\"config.json\")[3]\n    tenant_id = mod.config_reader.read_config_values(\"config.json\")[0]\n\n    ######################################################################\n    your_workspace_name = mod.config_reader.read_config_values(\"config.json\")[4]\n    print(\"Your Log Analytic Workspace: \" + your_workspace_name)\n    ######################################################################\nelse:\n    # Run this if you are using DSVM.  You need to copy the values from config.json, if the file has no value, then you need to go to Log Analytics Portal to get the information.\n    tenant_id = input('tenant_id:')\n    subscription_id = input('subscription_id:')\n    resource_group = input('resource_group:')\n    workspace_id = input('workspace_id:')\n    workspace_name = input('workspace_name:')\n    ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Authenticate to Log Analytics\nIf you are using user/device authentication, run the following cell. \n- Click the 'Copy code to clipboard and authenticate' button.\n- This will pop up an Azure Active Directory authentication dialog (in a new tab or browser window). The device code will have been copied to the clipboard. \n- Select the text box and paste (Ctrl-V/Cmd-V) the copied value. \n- You should then be redirected to a user authentication page where you should authenticate with a user account that has permission to query your Log Analytics workspace.\n\nUse the following syntax if you are authenticating using an Azure Active Directory AppId and Secret:\n```\n%kql loganalytics://tenant(aad_tenant).workspace(WORKSPACE_ID).clientid(client_id).clientsecret(client_secret)\n```\ninstead of\n```\n%kql loganalytics://code().workspace(WORKSPACE_ID)\n```"
    },
    {
      "metadata": {
        "tags": [
          "todo"
        ],
        "trusted": true
      },
      "cell_type": "code",
      "source": "WORKSPACE_ID = workspace_id\n    \nif not WORKSPACE_ID:\n    raise ValueError('No workspace selected.')\n\nmas.kql.load_kql_magic()\n\n%kql loganalytics://code().workspace(WORKSPACE_ID)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "tags": [
          "todo"
        ]
      },
      "cell_type": "markdown",
      "source": "<a id='getalertslist'></a>[Contents](#toc)\n# Get Alerts List\n\nSpecify a time range to search for alerts. One this is set run the following cell to retrieve any alerts in that time window.\nYou can change the time range and re-run the queries until you find the alerts that you want."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "alert_q_times = mas.QueryTime(units='day', max_before=20, before=5, max_after=1)\nalert_q_times.display()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": false,
        "trusted": true
      },
      "cell_type": "code",
      "source": "alert_counts = qry.list_alerts_counts(provs=[alert_q_times])\nalert_list = qry.list_alerts(provs=[alert_q_times])\nprint(len(alert_counts), ' distinct alert types')\nprint(len(alert_list), ' distinct alerts')\ndisplay(HTML('<h2>Alert Timeline</h2>'))\nnbdisp.display_timeline(data=alert_list, source_columns = ['AlertName', 'CompromisedEntity'], title='Alerts', height=200)\ndisplay(HTML('<h2>Top alerts</h2>'))\nalert_counts.head(20) # remove '.head(20)'' to see the full list grouped by AlertName",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "<a id='enteralertid'></a>[Contents](#toc)\n# Choose Alert to Investigate\nEither pick an alert from a list of retrieved alerts or paste the SystemAlertId into the text box in the following section."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Select alert from list\nAs you select an alert, the main properties will be shown below the list.\n\nUse the filter box to narrow down your search to any substring in the AlertName."
    },
    {
      "metadata": {
        "scrolled": false,
        "trusted": true
      },
      "cell_type": "code",
      "source": "alert_select = mas.AlertSelector(alerts=alert_list, action=nbdisp.display_alert)\nalert_select.display()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Or paste in an alert ID and fetch it\n**Skip this if you selected from the above list**"
    },
    {
      "metadata": {
        "scrolled": false,
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Allow alert to be selected\n# Allow subscription to be selected\nget_alert = mas.GetSingleAlert(action=nbdisp.display_alert)\nget_alert.display()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "<a id='extractalertproperties'></a>[Contents](#toc)\n## Extract properties and entities from Alert\nThis section extracts the alert information and entities into a SecurityAlert object allowing us to query the properties more reliably. \n\nIn particular, we use the alert to automatically provide parameters for queries and UI elements.\nSubsequent queries will use properties like the host name and derived properties such as the OS family (Linux or Windows) to adapt the query. Query time selectors like the one above will also default to an origin time that matches the alert selected.\n\nThe alert view below shows all of the main properties of the alert plus the extended property dictionary (if any) and JSON representations of the Entity."
    },
    {
      "metadata": {
        "scrolled": false,
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Extract entities and properties into a SecurityAlert class\nif alert_select.selected_alert is None:\n    sys.exit(\"Please select an alert before executing remaining cells.\")\n\nsecurity_alert = mas.SecurityAlert(alert_select.selected_alert)\nmas.disp.display_alert(security_alert, show_entities=True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "<a id='entitygraph'></a>[Contents](#toc)\n## Entity Graph\nDepending on the type of alert there may be one or more entities attached as properties. Entities are things like Host, Account, IpAddress, Process, etc. - essentially the 'nouns' of security investigation. Events and alerts are the things that link them in actions so can be thought of as the verbs. Entities are often related to other entities - for example a process will usually have a related file entity (the process image) and an Account entity (the context in which the process was running). Endpoint alerts typically always have a host entity (which could be a physical or virtual machine)."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Plot using Networkx/Matplotlib"
    },
    {
      "metadata": {
        "scrolled": false,
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Draw the graph using Networkx/Matplotlib\n%matplotlib inline\nalertentity_graph = mas.create_alert_graph(security_alert)\nnbdisp.draw_alert_entity_graph(alertentity_graph, width=15)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "tags": [
          "future"
        ],
        "trusted": true
      },
      "cell_type": "code",
      "source": "# from pyvis.network import Network\n# import math\n# # import networkx as nx\n# # G = Network()\n# # G.from_nx(alertentity_graph)\n# import holoviews as hv\n# hv.extension('bokeh')\n# %opts Graph [width=900 height=900]\n\n# %opts Graph [color_index='circle']\n# %opts Graph (node_size=20 edge_line_width=1)\n# %opts Graph [tools=['wheel_zoom', 'hover']]\n# padding = dict(x=(-1.2, 1.2), y=(-1.2, 1.2))\n\n# n_nodes = len(alertentity_graph.nodes)\n# k = 1 / (math.sqrt(n_nodes))\n\n# # hv_graph = hv.Graph.from_networkx(nx_graph, nx.layout.spring_layout, k=k).redim.range(**padding)\n# hv_graph = hv.Graph.from_networkx(alertentity_graph, nx.layout.spring_layout, k=k).redim.range(**padding)\n# labels = hv.Labels(\n#         {('x', 'y'): hv_graph.nodes.array([0, 1]), 'text': hv_graph.nodes.data['name']}, ## 'label' can be an array: has to be correct size!\n#         ['x', 'y'], \n#         'text').options(fontsize=8, cmap='viridis', yoffset=0.05)\n# hv_graph*labels",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "tags": [
          "todo"
        ]
      },
      "cell_type": "markdown",
      "source": "<a id='related_alerts'></a>[Contents](#toc)\n# Related Alerts\nFor a subset of entities in the alert we can search for any alerts that have that entity in common. Currently this query looks for alerts that share the same Host, Account or Process and lists them below. \n**Notes:**\n- Some alert types do not include all of these entity types.\n- The original alert will be included in the \"Related Alerts\" set if it occurs within the query time boundary set below.\n\nThe query time boundaries default to a longer period than when searching for the alert. You can extend the time boundary searched before or after the alert time. If the widget doesn't support the time boundary that you want you can change the max_before and max_after parameters in the call to QueryTime below to extend the possible time boundaries."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# set the origin time to the time of our alert\nquery_times = mas.QueryTime(units='day', origin_time=security_alert.TimeGenerated, \n                            max_before=28, max_after=1, before=5)\nquery_times.display()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": false,
        "trusted": true
      },
      "cell_type": "code",
      "source": "related_alerts = qry.list_related_alerts(provs=[query_times, security_alert])\n\nhost_alert_items = related_alerts\\\n    .query('host_match == @True')[['AlertType', 'StartTimeUtc']]\\\n    .groupby('AlertType').StartTimeUtc.agg('count').to_dict()\nacct_alert_items = related_alerts\\\n    .query('acct_match == @True')[['AlertType', 'StartTimeUtc']]\\\n    .groupby('AlertType').StartTimeUtc.agg('count').to_dict()\nproc_alert_items = related_alerts\\\n    .query('proc_match == @True')[['AlertType', 'StartTimeUtc']]\\\n    .groupby('AlertType').StartTimeUtc.agg('count').to_dict()\n\ndef print_related_alerts(alertDict, entityType, entityName):\n    if len(alertDict) > 0:\n        print('Found {} different alert types related to this {} (\\'{}\\')'.format(len(alertDict), entityType, entityName))\n        for (k,v) in alertDict.items():\n            print('    {}, Count of alerts: {}'.format(k, v))\n    else:\n        print('No alerts for {} entity \\'{}\\''.format(entityType, entityName))\n\nprint_related_alerts(host_alert_items, 'host', security_alert.hostname)\nprint_related_alerts(acct_alert_items, 'account', \n                     security_alert.primary_account.qualified_name if security_alert.primary_account\n                     else None)\nprint_related_alerts(proc_alert_items, 'process', \n                     security_alert.primary_process.ProcessFilePath if security_alert.primary_process\n                     else None)\nnbdisp.display_timeline(data=related_alerts, source_columns = ['AlertName'], title='Alerts', height=100)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Show these related alerts on a graph\nThis should indicate which entities the other alerts are related to.\n\nThis can be unreadable with a lot of alerts. Use the matplotlib interactive zoom control to zoom in to part of the graph."
    },
    {
      "metadata": {
        "scrolled": false,
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Draw a graph of this (add to entity graph)\n%matplotlib notebook\n%matplotlib inline\n\nrel_alert_graph = mas.add_related_alerts(related_alerts=related_alerts,\n                                         alertgraph=alertentity_graph)\nnbdisp.draw_alert_entity_graph(rel_alert_graph, width=15)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Browse List of Related Alerts\nSelect an Alert to view details. \n\nIf you want to investigate that alert - copy its *SystemAlertId* property and open a new instance of this notebook to investigate this alert."
    },
    {
      "metadata": {
        "scrolled": false,
        "trusted": true
      },
      "cell_type": "code",
      "source": "related_alerts['CompromisedEntity'] = related_alerts['Computer']\n\ndef disp_full_alert(alert):\n    global related_alert\n    related_alert = mas.SecurityAlert(alert)\n    nbdisp.display_alert(related_alert, show_entities=True)\n\nprint('Selected alert is available as \\'related_alert\\' variable.')\nrel_alert_select = mas.AlertSelector(alerts=related_alerts, action=disp_full_alert)\nrel_alert_select.display()\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "<a id='processtree'></a>[Contents](#toc)\n# Get Process Tree\nIf the alert has a process entity this section tries to retrieve the entire process tree to which that process belongs.\n\nNotes:\n- The alert must have a process entity\n- Only processes started within the query time boundary will be included\n- Ancestor and descented processes are retrieved to two levels (i.e. the parent and grandparent of the alert process plus any child and grandchild processes).\n- Sibling processes are the processes that share the same parent as the alert process\n- This can be a long-running query, especially if a wide time window is used! Caveat Emptor!\n\nThe source (alert) process is shown in red.\n\nWhat's shown for each process:\n- Each process line is indented according to its position in the tree hierarchy\n- Top line fields:\n  - \\[relationship to source process:lev# - where # is the hops away from the source process\\]\n  - Process creation date-time (UTC)\n  - Process Image path\n  - PID - Process Id\n  - SubjSess - the session Id of the process spawning the new process\n  - TargSess - the new session Id if the process is launched in another context/session. If 0/0x0 then the process is launched in the same session as its parent\n- Second line fields:\n  - Process command line\n  - Account - name of the account context in which the process is running"
    },
    {
      "metadata": {
        "scrolled": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "# set the origin time to the time of our alert\nquery_times = mas.QueryTime(units='minute', origin_time=security_alert.origin_time)\nquery_times.display()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "if security_alert.primary_process and security_alert.primary_process.ProcessId:\n    process_tree = qry.get_process_tree(provs=[query_times, security_alert])\n\n    # Print out the text view of the process tree\n    nbdisp.display_process_tree(process_tree)\nelse:\n    print('This alert has no process entity. See later in the notebook to retrieve all processes')\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "<a id='processtimeline'></a>[Contents](#toc)\n## Process TimeLine\nThis shows each process in the process tree on a timeline view.\n\nLabelling of individual process is very performance intensive and often results in nothing being displayed at all! Besides, for large numbers of processes it would likely result in an unreadable mess. \n\nYour main tools for negotiating the timeline are the Hover tool (toggled on and off by the speech bubble icon) and the wheel-zoom and pan tools (the former is an icon with an elipse and a magnifying glass, the latter is the crossed-arrows icon). The wheel zoom is particularly useful.\n\nAs you hover over each process it will display the image name, PID and commandline.\n\nAlso shown on the graphic is the timestamp line of the source/alert process."
    },
    {
      "metadata": {
        "scrolled": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Show timeline of events\nnbdisp.display_timeline(data=process_tree, alert=security_alert, title='Alert Process Session', height=250)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "<a id='process_clustering'></a>[Contents](#toc)\n# Other Processes on Host - Clustering\nSometimes you don't have a source process to work with. Other times it's just useful to see what else is going on on the host. This section retrieves all processes on the host within the time bounds\nset in the query times widget.\n\nYou can display the raw output of this by looking at the *processes_on_host* dataframe. Just copy this into a new cell and hit Ctrl-Enter.\n\nUsually though, the results return a lot of very repetitive and unintersting system processes so we attempt to cluster these to make the view easier to negotiate. \nTo do this we process the raw event list output to extract a few features that render strings (such as commandline)into numerical values. The default below uses the following features:\n- commandLineTokensFull - this is a count of common delimiters in the commandline \n  (given by this regex r'[\\s\\-\\\\/\\.,\"\\'|&:;%$()]'). The aim of this is to capture the commandline structure while ignoring variations on what is essentially the same pattern (e.g. temporary path GUIDs, target IP or host names, etc.)\n- pathScore - this sums the ordinal (character) value of each character in the path (so /bin/bash and /bin/bosh would have similar scores).\n- isSystemSession - 1 if this is a root/system session, 0 if anything else.\n\nThen we run a clustering algorithm (DBScan in this case) on the process list. The result groups similar (noisy) processes together and leaves unique process patterns as single-member clusters."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### Clustered Processes (i.e. processes that have a cluster size > 1)"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from msticpy.sectools.eventcluster import dbcluster_events, add_process_features\n\nprocesses_on_host = qry.list_processes(provs=[query_times, security_alert])\nfeature_procs = add_process_features(input_frame=processes_on_host,\n                                     path_separator=security_alert.path_separator)\n\n\n# you might need to play around with the max_cluster_distance parameter.\n# decreasing this gives more clusters.\n(clus_events, dbcluster, x_data) = dbcluster_events(data=feature_procs,\n                                                    cluster_columns=['commandlineTokensFull', \n                                                                     'pathScore', \n                                                                     'isSystemSession'],\n                                                    max_cluster_distance=0.0001)\nprint('Number of input events:', len(feature_procs))\nprint('Number of clustered events:', len(clus_events))\nclus_events[['ClusterSize', 'processName']][clus_events['ClusterSize'] > 1].plot.bar(x='processName', \n                                                                                     title='Process names with Cluster > 1', \n                                                                                     figsize=(12,3));",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": false,
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Looking at the variability of commandlines and process image paths\nimport seaborn as sns\nsns.set(style=\"darkgrid\")\n\nproc_plot = sns.catplot(y=\"processName\", x=\"commandlineTokensFull\", \n                        data=feature_procs.sort_values('processName'),\n                        kind='box', height=10)\nproc_plot.fig.suptitle('Variability of Commandline Tokens', x=1, y=1)\n\nproc_plot = sns.catplot(y=\"processName\", x=\"pathLogScore\", \n                        data=feature_procs.sort_values('processName'),\n                        kind='box', height=10, hue='isSystemSession')\nproc_plot.fig.suptitle('Variability of Path', x=1, y=1);",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "The top graph shows that, for a given process, some have a wide variability in their command line content while the majority have little or none. Looking at a couple of examples - like cmd.exe, powershell.exe, reg.exe, net.exe - we can recognize several common command line tools.\n\nThe second graph shows processes by full process path content. We wouldn't normally expect to see variation here - as is the cast with most. There is also quite a lot of variance in the score making it a useful proxy feature for unique path name (this means that proc1.exe and proc2.exe that have the same commandline score won't get collapsed into the same cluster).\n\nAny process with a spread of values here means that we are seeing the same process name (but not necessarily the same file) is being run from different locations."
    },
    {
      "metadata": {
        "scrolled": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "resp = input('View the clustered data? y/n')\nif resp == 'y':\n    display(clus_events.sort_values('TimeGenerated')[['TimeGenerated', 'LastEventTime',\n                                                      'NewProcessName', 'CommandLine', \n                                                      'ClusterSize', 'commandlineTokensFull',\n                                                      'pathScore', 'isSystemSession']])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Look at clusters for individual process names\ndef view_cluster(exe_name):\n    display(clus_events[['ClusterSize', 'processName', 'CommandLine', 'ClusterId']][clus_events['processName'] == exe_name])\nview_cluster('reg.exe')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": false,
        "tags": [
          "todo"
        ],
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Show all clustered processes\n\n# Create label with unqualified path\nlabelled_df = processes_on_host.copy()\nlabelled_df['label'] = labelled_df.apply(lambda x: x.NewProcessName.split(security_alert.path_separator)[-1], axis=1)\n\n%matplotlib inline\n#%matplotlib notebook\nplt.rcParams['figure.figsize'] = (15,10)\nnbdisp.plot_cluster(dbcluster, labelled_df, x_data, plot_label='label', plot_features=[0,1], verbose=False, cut_off=3,\n             xlabel='CmdLine Tokens', ylabel='Path Score');\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Time showing clustered vs. original data"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Show timeline of events - clustered events\nnbdisp.display_timeline(data=clus_events, overlay_data=processes_on_host, \n                         alert=security_alert, title='Distinct Host Processes (top) and All Proceses (bottom)')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "<a id='cmdlineiocs'></a>[Contents](#toc)\n# Base64 Decode and Check for IOCs\nThis section looks for Indicators of Compromise (IoC) within the data sets passed to it.\n\nThe first section looks at the commandline for the alert process (if any). It also looks for base64 encoded strings within the data - this is a common way of hiding attacker intent. It attempts to decode any strings that look like base64. Additionally, if the base64 decode operation returns any items that look like a base64 encoded string or file, a gzipped binary sequence, a zipped or tar archive, it will attempt to extract the contents before searching for potentially interesting items."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "process = security_alert.primary_process\nioc_extractor = sectools.IoCExtract()\n\nif process:\n    # if nothing is decoded this just returns the input string unchanged\n    base64_dec_str, _ = sectools.b64.unpack_items(input_string=process[\"CommandLine\"])\n    if base64_dec_str and '<decoded' in base64_dec_str:\n        print('Base64 encoded items found.')\n        print(base64_dec_str)\n        \n    # any IoCs in the string?\n    iocs_found = ioc_extractor.extract(base64_dec_str)\n    \n    if iocs_found:\n        print('\\nPotential IoCs found in alert process:')\n        display(iocs_found)\nelse:\n    print('Nothing to process')\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### If we have a process tree, look for IoCs in the whole data set\nYou can replace the data=process_tree parameter to ioc_extractor.extract() to pass other data frames.\nuse the columns parameter to specify which column or columns that you want to search."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "ioc_extractor = sectools.IoCExtract()\nioc_df = ioc_extractor.extract(data=process_tree, columns=['CommandLine'], os_family=security_alert.os_family)\nif len(ioc_df):\n    display(HTML(\"<h3>IoC patterns found in process tree.</h3>\"))\n    display(ioc_df)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### If any Base64 encoded strings, decode and search for IoCs in the results.\nFor simple strings the Base64 decoded output is straightforward. However for nested encodings this can get a little complex and difficult to represent in a tabular format.\n\n**Columns**\n - reference - The index of the row item in dotted notation in depth.seq pairs (e.g. 1.2.2.3 would be the 3 item at depth 3 that is a child of the 2nd item found at depth 1). This may not always be an accurate notation - it is mainly use to allow you to associate an individual row with the reference value contained in the full_decoded_string column of the topmost item).\n - original_string - the original string before decoding.\n - file_name - filename, if any (only if this is an item in zip or tar file).\n - file_type - a guess at the file type (this is currently elementary and only includes a few file types).\n - input_bytes - the decoded bytes as a Python bytes string.\n - decoded_string - the decoded string if it can be decoded as a UTF-8 or UTF-16 string. Note: binary sequences may often successfully decode as UTF-16 strings but, in these cases, the decodings are meaningless.\n - encoding_type - encoding type (UTF-8 or UTF-16) if a decoding was possible, otherwise 'binary'.\n - file_hashes - collection of file hashes for any decoded item.\n - md5 - md5 hash as a separate column.\n - sha1 - sha1 hash as a separate column.\n - sha256 - sha256 hash as a separate column.\n - printable_bytes - printable version of input_bytes as a string of \\xNN values\n - src_index - the index of the row in the input dataframe from which the data came.\n - full_decoded_string - the full decoded string with any decoded replacements. This is only really useful for top-level items, since nested items will only show the 'full' string representing the child fragment."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "dec_df = sectools.b64.unpack_items(data=process_tree, column='CommandLine')\nif len(dec_df) > 0:\n    display(HTML(\"<h3>Decoded base 64 command lines</h3>\"))\n    display(HTML(\"Warning - some binary patterns may be decodable as unicode strings\"))\n    display(dec_df[['full_decoded_string', 'original_string', 'decoded_string', 'input_bytes', 'file_hashes']])\n\n    ioc_dec_df = ioc_extractor.extract(data=dec_df, columns=['full_decoded_string'])\n    if len(ioc_dec_df):\n        display(HTML(\"<h3>IoC patterns found in base 64 decoded data</h3>\"))\n        display(ioc_dec_df)\n        ioc_df = ioc_df.append(ioc_dec_df ,ignore_index=True)\nelse:\n    print(\"No base64 encodings found.\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "hidden": true
      },
      "cell_type": "markdown",
      "source": "<a id='virustotallookup'></a>[Contents](#toc)\n## Virus Total Lookup\nThis section uses the popular Virus Total service to check any recovered IoCs against VTs database.\n\nTo use this you need an API key from virus total, which you can obtain here: https://www.virustotal.com/.\n\nNote that VT throttles requests for free API keys to 4/minute. If you are unable to process the entire data set, try splitting it and submitting smaller chunks.\n\n**Things to note:**\n- Virus Total lookups include file hashes, domains, IP addresses and URLs.\n- The returned data is slightly different depending on the input type\n- The VTLookup class tries to screen input data to prevent pointless lookups. E.g.:\n  - Only public IP Addresses will be submitted (no loopback, private address space, etc.)\n  - URLs with only local (unqualified) host parts will not be submitted.\n  - Domain names that are unqualified will not be submitted.\n  - Hash-like strings (e.g 'AAAAAAAAAAAAAAAAAA') that do not appear to have enough entropy to be a hash will not be submitted.\n\n**Output Columns**\n - Observable - The IoC observable submitted\n - IoCType - the IoC type\n - Status - the status of the submission request\n - ResponseCode - the VT response code\n - RawResponse - the entire raw json response\n - Resource - VT Resource\n - SourceIndex - The index of the Observable in the source DataFrame. You can use this to rejoin to your original data.\n - VerboseMsg - VT Verbose Message\n - ScanId - VT Scan ID if any\n - Permalink - VT Permanent URL describing the resource\n - Positives - If this is not zero, it indicates the number of malicious reports that VT holds for this observable.\n - MD5 - The MD5 hash, if any\n - SHA1 - The MD5 hash, if any\n - SHA256 - The MD5 hash, if any\n - ResolvedDomains - In the case of IP Addresses, this contains a list of all domains that resolve to this IP address\n - ResolvedIPs - In the case Domains, this contains a list of all IP addresses resolved from the domain.\n - DetectedUrls - Any malicious URLs associated with the observable."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "vt_key = mas.GetEnvironmentKey(env_var='VT_API_KEY',\n                           help_str='To obtain an API key sign up here https://www.virustotal.com/',\n                           prompt='Virus Total API key:')\nvt_key.display()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": false,
        "trusted": true
      },
      "cell_type": "code",
      "source": "if vt_key.value:\n    vt_lookup = sectools.VTLookup(vt_key.value, verbosity=2)\n\n    print(f'{len(ioc_df)} items in input frame')\n    supported_counts = {}\n    for ioc_type in vt_lookup.supported_ioc_types:\n        supported_counts[ioc_type] = len(ioc_df[ioc_df['IoCType'] == ioc_type])\n    print('Items in each category to be submitted to VirusTotal')\n    print('(Note: items have pre-filtering to remove obvious erroneous '\n          'data and false positives, such as private IPaddresses)')\n    print(supported_counts)\n    print('-' * 80)\n    vt_results = vt_lookup.lookup_iocs(data=ioc_df, type_col='IoCType', src_col='Observable')\n    \n    pos_vt_results = vt_results.query('Positives > 0')\n    if len(pos_vt_results) > 0:\n        display(HTML(f'<h3>{len(pos_vt_results)} Positive Results Found</h3>'))\n        display(pos_vt_results[['Observable', 'IoCType','Permalink', \n                                'ResolvedDomains', 'ResolvedIPs', \n                                'DetectedUrls', 'RawResponse']])\n    display(HTML('<h3>Other results</h3>'))\n    display(vt_results.query('Status == \\'Success\\''))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "To view the raw response for a specific row.\n```\nimport json\nrow_idx = 0 # The row number from one of the above dataframes\nraw_response = json.loads(pos_vt_results['RawResponse'].loc[row_idx])\nraw_response\n```"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "<a id='cmdlineonotherhosts'></a>[Contents](#toc)\n# Alert command line - Occurrence on other hosts in workspace\nTo get a sense of whether the alert process is something that is occuring on other hosts, run this section.\n\nThis might tell you that the alerted process is actually a commonly-run process and the alert is a false positive. Alternatively, it may tell you that a real infection or attack is happening on other hosts in your environment."
    },
    {
      "metadata": {
        "scrolled": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "# set the origin time to the time of our alert\nquery_times = mas.QueryTime(units='day', before=5, max_before=20,\n                            after=1, max_after=10,\n                            origin_time=security_alert.origin_time)\nquery_times.display()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": false,
        "trusted": true
      },
      "cell_type": "code",
      "source": "# API ILLUSTRATION - Find the query to use\nqry.list_queries()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "# API ILLUSTRATION - What does the query look like?\nqry.query_help('list_hosts_matching_commandline')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# This query needs a commandline parameter which isn't supplied\n# by default from the the alert \n# - so extract and escape this from the process\ncommandline = security_alert.primary_process.CommandLine\ncommandline = mas.utility.escape_windows_path(commandline)\n#commandline = commandline.replace('\\'', '\\\\\\'')\nproc_match_in_ws = qry.list_hosts_matching_commandline(provs=[query_times, security_alert],\n                                                                commandline=commandline)\n\n# Check the results\nif proc_match_in_ws is None or len(proc_match_in_ws) == 0:\n    print('No proceses with matching commandline found in on other hosts in workspace')\n    print('between', query_times.start, 'and', query_times.end)\nelse:\n    hosts = proc_match_in_ws['Computer'].drop_duplicates().shape[0]\n    processes = proc_match_in_ws.shape[0]\n    print('{numprocesses} proceses with matching commandline found on {numhosts} hosts in workspace'\\\n         .format(numprocesses=processes, numhosts=hosts))\n    print('between', query_times.start, 'and', query_times.end)\n    print('To examine these execute the dataframe \\'{}\\' in a new cell'.format('proc_match_in_ws'))\n    print(proc_match_in_ws[['TimeCreatedUtc','Computer', 'NewProcessName', 'CommandLine']].head())\n    ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "<a id='host_logons'></a>[Contents](#toc)\n# Host Logons\nThis section retrieves the logon events on the host in the alert.\n\nYou may want to use the query times to search over a broader range than the default."
    },
    {
      "metadata": {
        "scrolled": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "# set the origin time to the time of our alert\nquery_times = mas.QueryTime(units='day', origin_time=security_alert.origin_time,\n                           before=5, after=0, max_before=20, max_after=1)\nquery_times.display()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "hidden": true,
        "tags": [
          "todo"
        ]
      },
      "cell_type": "markdown",
      "source": "<a id='logonaccount'></a>[Contents](#toc)\n## Alert Logon Account\nThe logon associated with the process in the alert."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "if security_alert.primary_account:\n    logon_event = qry.get_host_logon(provs=[query_times, security_alert])\n    nbdisp.display_logon_data(logon_event, security_alert)\nelse:\n    print('No account entity in the source alert.')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### All Host Logons\nSince the number of logon events may be large and, in the case of system logons, very repetitive, we use clustering to try to identity logons with unique characteristics.\n\nIn this case we use the numeric score of the account name and the logon type (i.e. interactive, service, etc.). The results of the clustered logons are shown below along with a more detailed, readable printout of the logon event information. The data here will vary depending on whether this is a Windows or Linux host."
    },
    {
      "metadata": {
        "scrolled": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "from msticpy.sectools.eventcluster import dbcluster_events, add_process_features, _string_score\n\nhost_logons = qry.list_host_logons(provs=[query_times, security_alert])\nif len(host_logons) > 0:\n    logon_features = host_logons.copy()\n    logon_features['AccountNum'] = host_logons.apply(lambda x: _string_score(x.Account), axis=1)\n    logon_features['LogonHour'] = host_logons.apply(lambda x: x.TimeGenerated.hour, axis=1)\n\n    # you might need to play around with the max_cluster_distance parameter.\n    # decreasing this gives more clusters.\n    (clus_logons, _, _) = dbcluster_events(data=logon_features, time_column='TimeGenerated',\n                                           cluster_columns=['AccountNum',\n                                                            'LogonType'],\n                                                             max_cluster_distance=0.0001)\n    print('Number of input events:', len(host_logons))\n    print('Number of clustered events:', len(clus_logons))\n    print('\\nDistinct host logon patterns:')\n    display(clus_logons.sort_values('TimeGenerated'))\nelse:\n    print('No logon events found for host.')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Display logon details\nnbdisp.display_logon_data(clus_logons, security_alert)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Comparing All Logons with Clustered results relative to Alert time line"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Show timeline of events - all logons + clustered logons\nnbdisp.display_timeline(data=host_logons, overlay_data=clus_logons,\n                         alert=security_alert, \n                         source_columns=['Account', 'LogonType'],\n                         title='All Host Logons')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### View Process Session and Logon Events in Timelines\nThis shows the timeline of the clustered logon events with the process tree obtained earlier. This allows you to get a sense of which logon was responsible for the process tree session whether any additional logons (e.g. creating a process as another user) might be associated with the alert timeline.\n\n*Note you should use the pan and zoom tools to align the timelines since the data may be over different time ranges.*"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Show timeline of events - all events\nnbdisp.display_timeline(data=clus_logons, source_columns=['Account', 'LogonType'],\n                         alert=security_alert,\n                         title='Clustered Host Logons', height=200)\nnbdisp.display_timeline(data=process_tree, alert=security_alert, title='Alert Process Session', height=200)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Counts of Logon types by Account\nhost_logons[['Account', 'LogonType', 'TimeGenerated']].groupby(['Account','LogonType']).count()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "hidden": true
      },
      "cell_type": "markdown",
      "source": "<a id='failed logons'></a>[Contents](#toc)\n## Failed Logons"
    },
    {
      "metadata": {
        "hidden": true,
        "scrolled": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "failedLogons = qry.list_host_logon_failures(provs=[query_times, security_alert])\nif failedLogons.shape[0] == 0:\n    display(print('No logon failures recorded for this host between {security_alert.start} and {security_alert.start}'))\n\nfailedLogons",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "hidden": true
      },
      "cell_type": "markdown",
      "source": "<a id='appendices'></a>[Contents](#toc)\n# Appendices"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Available DataFrames"
    },
    {
      "metadata": {
        "scrolled": false,
        "trusted": true
      },
      "cell_type": "code",
      "source": "print('List of current DataFrames in Notebook')\nprint('-' * 50)\ncurrent_vars = list(locals().keys())\nfor var_name in current_vars:\n    if isinstance(locals()[var_name], pd.DataFrame) and not var_name.startswith('_'):\n        print(var_name)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Saving Data to CSV\nTo save the contents of a pandas DataFrame to an CSV\nuse the following syntax\n```\nhost_logons.to_csv('host_logons.csv')\n```"
    },
    {
      "metadata": {
        "heading_collapsed": true,
        "tags": [
          "todo"
        ]
      },
      "cell_type": "markdown",
      "source": "## Saving Data to Excel\nTo save the contents of a pandas DataFrame to an Excel spreadsheet\nuse the following syntax\n```\nwriter = pd.ExcelWriter('myWorksheet.xlsx')\nmy_data_frame.to_excel(writer,'Sheet1')\nwriter.save()\n```"
    }
  ],
  "metadata": {
    "celltoolbar": "Tags",
    "hide_input": false,
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    },
    "toc": {
      "nav_menu": {
        "height": "318.996px",
        "width": "320.994px"
      },
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "base_numbering": 1,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "width": "273px",
        "left": "10px",
        "top": "150px"
      },
      "toc_section_display": true,
      "toc_window_display": true
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "position": {
        "height": "406.193px",
        "left": "1468.4px",
        "right": "20px",
        "top": "120px",
        "width": "456.572px"
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}